{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"' saved_model'.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uDYnrvxDohOo","colab_type":"text"},"source":["Please run the code line by line.\n","\n","1. Link to your google drive. Please run the first line of code.\n","2. Dataset preparation. Please put the test data(preprocessed in generatedata.m) in the folder of '\\data7_weight\\test' and upload the folder '\\data7_weight' in your google drive. \n","3. Upload model. Please upload the folder '/training_checkpoints' in the workspace.\n","4. Add blank folder of result. Please add the blank folder '/result' in the workspace. The .npy result file will be saved in it."]},{"cell_type":"code","metadata":{"id":"tQq4qJNKcEfv","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"qmkj-80IHxnd","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YfIk2es3hJEd","colab":{}},"source":["import tensorflow as tf\n","\n","import os\n","import time\n","\n","from matplotlib import pyplot as plt\n","from IPython import display\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import tensorflow as tf\n","tf.test.gpu_device_name()\n","!pip install -U tensorboard\n","\n","PATH = '/content/drive/My Drive/data7_weight/' \n","BUFFER_SIZE = 400\n","BATCH_SIZE = 1\n","IMG_WIDTH = 256\n","IMG_HEIGHT = 256\n","LAMBDA = 30\n","OUTPUT_CHANNELS = 1\n","\n","\n","\n","def rgb2gray(rgb):\n","  return tf.cond(tf.equal(rgb.shape[2],1),lambda: rgb, lambda: np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]),)\n","\n","def load(image_file):\n","  image = tf.io.read_file(image_file)\n","  image = tf.image.decode_jpeg(image)\n","\n","  w = tf.shape(image)[1]\n","\n","  w = w // 2\n","  real_image = image[:, :w, :]\n","  input_image = image[:, w:, :]\n","\n","  input_image = tf.cast(input_image, tf.float32)\n","  real_image = tf.cast(real_image, tf.float32)\n","\n","  return input_image, real_image\n","def resize(input_image, real_image, height, width):\n","  input_image = tf.image.resize(input_image, [height, width],\n","                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","  real_image = tf.image.resize(real_image, [height, width],\n","                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","\n","  return input_image, real_image\n","\n","def random_crop(input_image, real_image):\n","  stacked_image = tf.stack([input_image, real_image], axis=0)\n","  cropped_image = tf.image.random_crop(\n","      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 1])\n","\n","  return cropped_image[0], cropped_image[1]\n"," \n","\n","def normalize(input_image, real_image):\n","  input_image = (input_image / 127.5) - 1\n","  real_image = (real_image / 127.5) - 1\n","\n","  return input_image, real_image\n"," \n","\n","def load_image_train(image_file):\n","  input_image, real_image = load(image_file)\n","  input_image, real_image = normalize(input_image, real_image)\n","\n","  return input_image, real_image\n","\n","def load_image_test(image_file):\n","  input_image, real_image = load(image_file)\n","\n","  input_image, real_image = resize(input_image, real_image,\n","                                   IMG_HEIGHT, IMG_WIDTH)\n","  input_image, real_image = normalize(input_image, real_image)\n","\n","  return input_image, real_image\n","\n","\n","def downsample(filters, size, apply_batchnorm=True):\n","  initializer = tf.random_normal_initializer(0., 0.02)\n","\n","  result = tf.keras.Sequential()\n","  result.add(\n","      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n","                             kernel_initializer=initializer, use_bias=False))\n","\n","  if apply_batchnorm:\n","    result.add(tf.keras.layers.BatchNormalization())\n","\n","  result.add(tf.keras.layers.LeakyReLU())\n","\n","  return result\n","\n","def upsample(filters, size, apply_dropout=False):\n","  initializer = tf.random_normal_initializer(0., 0.02)\n","\n","  result = tf.keras.Sequential()\n","  result.add(\n","    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n","                                    padding='same',\n","                                    kernel_initializer=initializer,\n","                                    use_bias=False))\n","\n","  result.add(tf.keras.layers.BatchNormalization())\n","\n","  if apply_dropout:\n","      result.add(tf.keras.layers.Dropout(0.5))\n","\n","  result.add(tf.keras.layers.ReLU())\n","\n","  return result\n","\n","def Generator():\n","  inputs = tf.keras.layers.Input(shape=[256,256,1])\n","\n","  down_stack = [\n","    downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n","    downsample(128, 4), # (bs, 64, 64, 128)\n","    downsample(256, 4), # (bs, 32, 32, 256)\n","    downsample(512, 4), # (bs, 16, 16, 512)\n","    downsample(512, 4), # (bs, 8, 8, 512)\n","    downsample(512, 4), # (bs, 4, 4, 512)\n","    downsample(512, 4), # (bs, 2, 2, 512)\n","    downsample(512, 4), # (bs, 1, 1, 512)\n","  ]\n","\n","  up_stack = [\n","    upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n","    upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n","    upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n","    upsample(512, 4), # (bs, 16, 16, 1024)\n","    upsample(256, 4), # (bs, 32, 32, 512)\n","    upsample(128, 4), # (bs, 64, 64, 256)\n","    upsample(64, 4), # (bs, 128, 128, 128)\n","  ]\n","\n","  initializer = tf.random_normal_initializer(0., 0.02)\n","  last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n","                                         strides=2,\n","                                         padding='same',\n","                                         kernel_initializer=initializer,\n","                                         activation='tanh') # (bs, 256, 256, 3)\n","\n","  x = inputs\n","\n","\n","  skips = []\n","  for down in down_stack:\n","    x = down(x)\n","    skips.append(x)\n","\n","  skips = reversed(skips[:-1])\n","\n","\n","  for up, skip in zip(up_stack, skips):\n","    x = up(x)\n","    x = tf.keras.layers.Concatenate()([x, skip])\n","\n","  x = last(x)\n","\n","  return tf.keras.Model(inputs=inputs, outputs=x)\n","\n","def generator_loss(disc_generated_output, gen_output, target):\n","  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n","\n","  # mean absolute error\n","  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n","\n","  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n","\n","  return total_gen_loss, gan_loss, l1_loss\n","\n","def Discriminator():\n","  initializer = tf.random_normal_initializer(0., 0.02)\n","\n","  inp = tf.keras.layers.Input(shape=[256, 256, 1], name='input_image')\n","  tar = tf.keras.layers.Input(shape=[256, 256, 1], name='target_image')\n","\n","  x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n","\n","  down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n","  down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n","  down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n","\n","  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n","  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n","                                kernel_initializer=initializer,\n","                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n","\n","  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n","\n","  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n","\n","  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n","\n","  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n","                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n","\n","  return tf.keras.Model(inputs=[inp, tar], outputs=last)\n","\n","def discriminator_loss(disc_real_output, disc_generated_output):\n","  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n","\n","  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n","\n","  total_disc_loss = real_loss + generated_loss\n","\n","  return total_disc_loss\n","\n","def generate_images(model, test_input, tar):\n","  prediction = model(test_input, training=True)\n","  plt.figure(figsize=(15,15))\n","\n","  display_list = [test_input[0], tar[0], prediction[0]]\n","  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n","\n","  for i in range(3):\n","    plt.subplot(1, 3, i+1)\n","    plt.title(title[i])\n"," \n","    imt = display_list[i] * 0.5 + 0.5;\n","    imt = imt[:,:,0]\n","    plt.imshow(imt,cmap=plt.get_cmap('gray'))\n","    plt.axis('off')\n","  plt.show()\n","\n","@tf.function\n","def train_step(input_image, target, epoch):\n","  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","    \n","   \n","    input_image = input_image[:,:,:,0]\n","    target = target[:,:,:,0]\n","    \n","    gen_output = generator(input_image, training=True)\n","\n","    disc_real_output = discriminator([input_image, target], training=True)\n","    disc_generated_output = discriminator([input_image, gen_output], training=True)\n","\n","    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n","    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n","\n","  generator_gradients = gen_tape.gradient(gen_total_loss,\n","                                          generator.trainable_variables)\n","  discriminator_gradients = disc_tape.gradient(disc_loss,\n","                                               discriminator.trainable_variables)\n","\n","  generator_optimizer.apply_gradients(zip(generator_gradients,\n","                                          generator.trainable_variables))\n","  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n","                                              discriminator.trainable_variables))\n","\n","  with summary_writer.as_default():\n","    tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n","    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n","    tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n","    tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n","def fit(train_ds, epochs, test_ds):\n","  \n","  for epoch in range(epochs): \n","    start = time.time()\n","    display.clear_output(wait=True)\n","\n","    for example_input, example_target in test_ds.take(1):\n","      generate_images(generator, example_input, example_target)\n","    print(\"Epoch: \", epoch)\n","\n","    # Train\n","    for n, (input_image, target) in train_ds.enumerate():\n","      print('.', end='')\n","      if (n+1) % 100 == 0:\n","        print()\n","      train_step(input_image, target, epoch)\n","    print()\n","\n","    if (epoch + 1) % 100 == 0:\n","      checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n","                                                        time.time()-start))\n","  checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","def generateandsave_images(model, test_input, tar,nid):\n","  prediction = model(test_input, training=True)\n","  np.save(os.path.join('/result/'+str(nid)+'.npy'), prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SQHmYSmk8b4b","colab":{}},"source":["test_dataset = tf.data.Dataset.list_files(PATH+'test/*.jpg')\n","test_dataset = test_dataset.map(load_image_test)\n","test_dataset = test_dataset.batch(BATCH_SIZE)\n","generator = Generator()\n","discriminator = Discriminator()\n","loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","checkpoint_dir = '/training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n","                                 discriminator_optimizer=discriminator_optimizer,\n","                                 generator=generator,\n","                                 discriminator=discriminator)\n","checkpoint_dir = '/training_checkpoints'#/home \n","!ls {checkpoint_dir}\n","checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p6fPLbXVY7Zl","colab_type":"code","colab":{}},"source":["%%time\n","nid = 1\n","for inp, tar in test_dataset.take(90):\n","  generateandsave_images(generator, inp, tar,nid)\n","  nid = nid+1"],"execution_count":null,"outputs":[]}]}